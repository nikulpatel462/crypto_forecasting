{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda update scikit-learn -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, clone, RegressorMixin\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import lightgbm\n",
    "\n",
    "USE_GPU = False # for lgbm model training\n",
    "\n",
    "device_type = \"gpu\" if USE_GPU else \"cpu\"\n",
    "\n",
    "\n",
    "# sys.path.append(\"/home/gresearch_crypto\")\n",
    "sys.path.append(\"gresearch_crypto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gresearch_crypto\n",
    "env = gresearch_crypto.make_env()\n",
    "\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" (Vastly) simplified submission functions to go in the submission notebook.\n",
    "\n",
    "Optimised for speed (at the expense of feature quality) to stay in the submission time limit.\n",
    "\n",
    "Contains no dependencies on the library functions to avoid having to clone + install a private git repo.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def bar_feats_minimal(df):\n",
    "    \"\"\"Augment the given dataframe in place with some features for each bar.\"\"\"\n",
    "    midpoint = (df[\"Open\"] + df[\"Close\"]) / 2\n",
    "    feats = {\n",
    "        \"rel_avg\": df[\"VWAP\"] / midpoint,\n",
    "        \"avg_t_size\": (df[\"Volume\"] / df[\"Count\"])\n",
    "        ** (1 / 10),  # average # of units per transaction\n",
    "        \"dollar_vol\": np.log(df[\"Volume\"] * df[\"VWAP\"]),  # dollar volume traded\n",
    "        \"rel_dev\": ((df[\"High\"] - df[\"Low\"]) / midpoint) ** (1 / 3),\n",
    "        \"shadow_diff\": (df[\"High\"] + df[\"Low\"]) / (2 * midpoint) - 1,\n",
    "    }\n",
    "    for name, feat in feats.items():\n",
    "        df.loc[:, name] = feat\n",
    "\n",
    "\n",
    "def ts_feats_minimal(df, window, price_mom_windows, include_target=True):\n",
    "    \"\"\"Add rolling z-score features including price momentum features and the target + target scale.\n",
    "    Assumes index is timestamps + Asset_IDs\n",
    "\n",
    "    Warning: changes input df in-place to save memory\n",
    "    \"\"\"\n",
    "    to_z_score = [\n",
    "        \"rel_avg\",\n",
    "        \"avg_t_size\",\n",
    "        \"shadow_diff\",\n",
    "        \"dollar_vol\",\n",
    "        \"rel_dev\",\n",
    "    ]\n",
    "\n",
    "    log_close_grp = df[[\"Close\"]].groupby(level=\"Asset_ID\", as_index=False)\n",
    "\n",
    "    for mom_window in price_mom_windows:\n",
    "        feat_name = f\"price_mom_{mom_window}\"\n",
    "        df.loc[:, feat_name] = log_close_grp.diff(mom_window)[\"Close\"]\n",
    "        to_z_score.append(feat_name)\n",
    "\n",
    "    min_periods = max(1, window // 10)\n",
    "    df_grp = (\n",
    "        df[to_z_score]\n",
    "        .groupby(level=\"Asset_ID\", as_index=False)\n",
    "        .rolling(window, min_periods=min_periods)\n",
    "    )\n",
    "\n",
    "    roll_mean = df_grp.mean().drop(columns=\"Asset_ID\").fillna(0)\n",
    "    roll_std = df_grp.std().drop(columns=\"Asset_ID\").ffill().fillna(1)\n",
    "\n",
    "    norm_feats = ((df[to_z_score] - roll_mean) / roll_std).rename(\n",
    "        mapper=lambda x: \"roll_\" + x, axis=\"columns\"\n",
    "    )\n",
    "\n",
    "    norm_feats.loc[:, \"target_scale\"] = roll_std[\"price_mom_15\"]\n",
    "\n",
    "    if include_target:  # FIXME: potentially confusing target naming convention\n",
    "        norm_feats.loc[:, \"scaled_target\"] = df[\"Target\"] / norm_feats[\"target_scale\"]\n",
    "        norm_feats.loc[:, \"target\"] = df[\"Target\"]\n",
    "\n",
    "    return norm_feats\n",
    "\n",
    "\n",
    "def all_feats_minimal(df, include_target=True):\n",
    "    \"\"\"Minimal version of all_feats\"\"\"\n",
    "    price_mom_windows = (1, 5, 15, 80)\n",
    "    window = 15\n",
    "\n",
    "    bar_feats_minimal(df)  # augment in-place with bar features\n",
    "    df.drop(\n",
    "        columns=[\"Count\", \"Open\", \"High\", \"Low\", \"Volume\", \"VWAP\"], inplace=True\n",
    "    )  # drop unused columns\n",
    "\n",
    "    df.set_index([\"timestamp\", \"Asset_ID\"], inplace=True)\n",
    "\n",
    "    return ts_feats_minimal(df, window, price_mom_windows, include_target)\n",
    "\n",
    "\n",
    "def last_n_ts_df(df, lookback, buffer=100):\n",
    "    \"\"\"Returns the last rows of df where the timestamp is in the last n of all\n",
    "    timestamps. This is to concatenate with new data provided by the API so that\n",
    "    rolling calculations can be performed.\n",
    "\n",
    "    Warning: assumes df is ordered by timestamps, and could return more data than\n",
    "    requested.\n",
    "    \"\"\"\n",
    "    n_assets = 14\n",
    "    return df.iloc[-(n_assets * lookback + buffer) :]\n",
    "\n",
    "\n",
    "def concat_old_new(old_data, new_data):\n",
    "    \"\"\"Concatenate old and new dfs for feature construction. Ensures\n",
    "    any overlapping timestamps + assetids in the old df are discarded.\n",
    "    \"\"\"\n",
    "    return pd.concat([old_data, new_data.drop(columns=\"row_id\")], ignore_index=True)\n",
    "\n",
    "\n",
    "def subset_test_index(data, orig_data):\n",
    "    \"\"\"Subset the prepred data df on the original test timestamps + assetids\"\"\"\n",
    "    orig_index = pd.MultiIndex.from_frame(orig_data[[\"timestamp\", \"Asset_ID\"]])\n",
    "    return data.loc[orig_index]\n",
    "\n",
    "\n",
    "def join_rowids(preds, orig_test):\n",
    "    \"\"\"Join our predictions df with the rowids in the supplied test data df\"\"\"\n",
    "    orig_join_on = orig_test[[\"timestamp\", \"Asset_ID\", \"row_id\"]].set_index(\n",
    "        [\"timestamp\", \"Asset_ID\"]\n",
    "    )\n",
    "    return preds.join(orig_join_on).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def predict_loop(model, prev_data, new_data, sample_pred_df, n_to_keep):\n",
    "    \"\"\"Function for looping over in env.iter_test():\n",
    "    - Concatenate previous + new data\n",
    "    - Cache last n rows of this df\n",
    "    - Calculate new features\n",
    "    - Drop rows to match the original training timestamps + asset ids\n",
    "    - Calculate predictions on this subset\n",
    "    - Join with the given row ids in the sample predictions df\n",
    "\n",
    "    Returns: last n rows from prev + new data, predictions df\n",
    "    \"\"\"\n",
    "    concat_data = concat_old_new(prev_data, new_data)\n",
    "    last_n = last_n_ts_df(concat_data, n_to_keep)\n",
    "    feats = all_feats_minimal(concat_data, include_target=False).fillna(0)\n",
    "    feats = subset_test_index(feats, new_data)\n",
    "    preds = model.predict(feats).rename(\"Target\").to_frame()\n",
    "    return last_n, join_rowids(preds, new_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_names(data_cols):\n",
    "    \"\"\"Take single/multiindex columns from a pandas df of features + targets\n",
    "    and return only the feature names.\n",
    "    \"\"\"\n",
    "    if isinstance(data_cols, pd.MultiIndex):\n",
    "        data_cols = data_cols.get_level_values(0).unique()\n",
    "\n",
    "    return [k for k in data_cols if \"target\" not in k]\n",
    "\n",
    "\n",
    "def get_xy_arrays(data_df):\n",
    "    \"\"\"Returns a tuple of numpy arrays: features, scaled targets\"\"\"\n",
    "    features = feature_names(data_df.columns)\n",
    "    try:\n",
    "        target = data_df[\"scaled_target\"].values\n",
    "    except:\n",
    "        target = None\n",
    "    return data_df[features].values, target\n",
    "\n",
    "\n",
    "def weighted_correlation(a, b, weights):\n",
    "    \"\"\"Evaluation metric copied from the discussion page\n",
    "    https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/291845\n",
    "\n",
    "    Excpects columns of actual targets, predictions and asset weights\n",
    "\n",
    "    Args:\n",
    "    - a, b: the actual and predicted weights\n",
    "    - weights: the associated asset weights\n",
    "    \"\"\"\n",
    "    w = np.ravel(weights)\n",
    "    a = np.ravel(a)\n",
    "    b = np.ravel(b)\n",
    "\n",
    "    sum_w = np.sum(w)\n",
    "    mean_a = np.sum(a * w) / sum_w\n",
    "    mean_b = np.sum(b * w) / sum_w\n",
    "    var_a = np.sum(w * np.square(a - mean_a)) / sum_w\n",
    "    var_b = np.sum(w * np.square(b - mean_b)) / sum_w\n",
    "\n",
    "    cov = np.sum((a * b * w)) / np.sum(w) - mean_a * mean_b\n",
    "    corr = cov / np.sqrt(var_a * var_b)\n",
    "\n",
    "    return corr\n",
    "\n",
    "\n",
    "\n",
    "def score_from_df(pred_df, X):\n",
    "    \"\"\"Ensure indices are aligned before calculating the weighted correlation\n",
    "    on the given predictions df.\n",
    "\n",
    "    Note: the score will be nan if one df contains index values not found in the other.\n",
    "    This likely indicates a bug in generating predictions since the predictions should\n",
    "    have been calculated using X, so the indices should be the same in some order.\n",
    "    \"\"\"\n",
    "    pred_df_reindexed = pred_df.reindex(index=X.index)\n",
    "    return weighted_correlation(\n",
    "        X.target.values,\n",
    "        pred_df_reindexed.values,\n",
    "        X.target_weight.values,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def score_pool_model(model, X):\n",
    "    \"\"\"Convenience function for generating predictions and passing to score_from_df\"\"\"\n",
    "    preds = model.predict(X)\n",
    "    return score_from_df(preds, X)\n",
    "\n",
    "\n",
    "class PoolRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"Helper class for fitting pool models.\n",
    "\n",
    "    Notes:\n",
    "    - This depends on the input X being a pandas df. sklearn (deliberately) tends not\n",
    "    to work well with pandas, but we don't use sklearn functionality extensively here\n",
    "    and what we do use will be okay (for indexing sklearn seems to take care of things,\n",
    "    see: https://github.com/scikit-learn/scikit-learn/blob/0d378913be6d7e485b792ea36e9268be31ed52d0/sklearn/utils/__init__.py#L307)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_model, clusters: dict):\n",
    "        self.base_model = base_model\n",
    "        self.clusters = clusters\n",
    "        self.asset_ids_ = reduce(lambda x, y: [*x, *y], clusters.values())\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None, **fit_kwargs):\n",
    "        \"\"\"Expects a long df using the \"targets\" column as the targets, and\n",
    "        any column without \"target\" in the name is used as a feature. Fit one\n",
    "        model for each given cluster.\n",
    "\n",
    "        Note: the case where each cluster has size 1 is the single asset model.\n",
    "        \"\"\"\n",
    "        self.models_ = {}\n",
    "        for cluster, asset_ids in self.clusters.items():\n",
    "            X_subset, y_subset = get_xy_arrays(X.loc[(slice(None), list(asset_ids)), :])\n",
    "            model_clone = clone(self.base_model)\n",
    "            model_clone.fit(\n",
    "                X_subset, y_subset, **fit_kwargs\n",
    "            )  # fit separately for compatibility with Keras\n",
    "            self.models_[cluster] = model_clone\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X) -> pd.DataFrame:\n",
    "        \"\"\"Take a long df of features and return a wide df of predictions\n",
    "        with asset_ids as columns.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for cluster, asset_ids in self.clusters.items():\n",
    "            X_subset = X.loc[(slice(None), asset_ids), :]\n",
    "            cluster_preds = scale_predictions(\n",
    "                self.models_[cluster], get_xy_arrays(X_subset)[0], X_subset.target_scale\n",
    "            )\n",
    "            preds.append(pd.Series(cluster_preds, index=X_subset.index))\n",
    "            # asset_preds = self.models_[asset_id].predict(get_xy_arrays(X_subset)[0])\n",
    "            # asset_preds = pd.Series(asset_preds, index=X_subset.index)\n",
    "            # preds[asset_id] = asset_preds * X_subset.target_scale # scale back to returns predictions\n",
    "\n",
    "        return pd.concat(preds).reindex(index=X.index)  # same order as input df\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        \"\"\"Return the weighted correlation between all predictions\"\"\"\n",
    "        return score_pool_model(self, X)\n",
    "\n",
    "\n",
    "class PoolVotingRegressor(RegressorMixin):\n",
    "    \"\"\"Wrapper around VotingRegressor intended for use with PoolRegressors.\n",
    "    In particular:\n",
    "    - change the default scoring function to weighted regression\n",
    "    - keep the original pandas indices to predictions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators, weights=None):\n",
    "        self.estimators = estimators\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        empty_y = np.empty_like(X.iloc[:, 0])\n",
    "        self.voting_regressor_ = VotingRegressor(\n",
    "            estimators=self.estimators, weights=self.weights\n",
    "        )\n",
    "        self.voting_regressor_.fit(X, empty_y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Adds the original pandas index of X to the output of the wrapped\n",
    "        VotingRegressor.\n",
    "        \"\"\"\n",
    "        preds = self.voting_regressor_.predict(X)\n",
    "        return pd.Series(preds, index=X.index)\n",
    "\n",
    "    def score(self, X, y=None):  # FIXME: duplication from PoolRegressor\n",
    "        \"\"\"Return the weighted correlation between all predictions\"\"\"\n",
    "        return score_pool_model(self, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {\n",
    "    0: (4, 8, 10, 11),\n",
    "    2: (0, 3, 12, 7), # move 7 in this cluster\n",
    "    3: (2, 5, 13),\n",
    "    4: (1, 6, 9),\n",
    "} # arbitrary cluster labels\n",
    "\n",
    "\n",
    "\n",
    "final_allocations = {\n",
    "    'pool_lasso': 0.13803354577335214,\n",
    "    'pool_LGBM': 0.10673472669853526,\n",
    "    'single_lasso': 0.16562975805884267,\n",
    "    'single_LGBM': 0.14721038027645952,\n",
    "    'pool_all_lasso': 0.21147431517754645,\n",
    "    'pool_all_LGBM': 0.23091727401526385,\n",
    "}\n",
    "\n",
    "all_assetids = list(range(14))\n",
    "\n",
    "pool_params = {\n",
    "    \"lasso\": {\n",
    "        \"model\": Lasso(),\n",
    "        \"params\": {\"alpha\": 0.0022222223000000004, \"fit_intercept\": False},\n",
    "    },\n",
    "    \"LGBM\": {\n",
    "        \"model\": lightgbm.LGBMRegressor(device_type=device_type),\n",
    "        \"params\": {\"learning_rate\": 0.01, \"lambda_l1\": 0.0, \"n_estimators\": 400, \"alpha\": 3}\n",
    "    },\n",
    "}\n",
    "\n",
    "single_params = {\n",
    "    \"lasso\": {\n",
    "        \"model\": Lasso(),\n",
    "        \"params\": {\"alpha\": 0.011111111188888889, \"fit_intercept\": False},\n",
    "    },\n",
    "    \"LGBM\": {\n",
    "        \"model\": lightgbm.LGBMRegressor(device_type=device_type),\n",
    "        \"params\": {\"learning_rate\": 0.01, \"lambda_l1\": 0.03, \"n_estimators\": 100, \"alpha\": 3}\n",
    "    },\n",
    "}\n",
    "\n",
    "all_params = {\n",
    "    \"lasso\": {\n",
    "        \"model\": Lasso(),\n",
    "        \"params\": {\"alpha\": 0.016733333333333333, \"fit_intercept\": False},\n",
    "    },\n",
    "    \"LGBM\": {\n",
    "        \"model\": lightgbm.LGBMRegressor(device_type=device_type),\n",
    "        \"params\": {\"learning_rate\": 0.02, \"lambda_l1\": 0.01, \"n_estimators\": 200}\n",
    "    },\n",
    "}\n",
    "\n",
    "param_dict = {\n",
    "    \"pool\": {\n",
    "        \"params\": pool_params,\n",
    "        \"clusters\": clusters,\n",
    "    },\n",
    "    \"single\": {\n",
    "        \"params\": single_params,\n",
    "        \"clusters\": {k: [k] for k in all_assetids},\n",
    "    },\n",
    "    \"pool_all\": {\n",
    "        \"params\": all_params,\n",
    "        \"clusters\": {-1: all_assetids},\n",
    "    },\n",
    "}\n",
    "\n",
    "all_models = {\n",
    "    f\"{setup}_{model_type}\": PoolRegressor(model[\"model\"].set_params(**model[\"params\"]), clusters=model_dict[\"clusters\"])\n",
    "    for setup, model_dict in param_dict.items()\n",
    "    for model_type, model in model_dict[\"params\"].items()\n",
    "}\n",
    "models_list = [(k, model) for k, model in all_models.items()]\n",
    "model_weight_list = [final_allocations[k] for k in all_models] # ensure in same order\n",
    "\n",
    "voting_model = PoolVotingRegressor(estimators=models_list, weights=model_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = all_feats_minimal(train_data.iloc[-100000:].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PoolVotingRegressor at 0x7f35569d6350>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_model.fit(feats.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp   Asset_ID\n",
       "1631758440  9           0.006814\n",
       "            10          0.039525\n",
       "            11         -0.056496\n",
       "            12         -0.000004\n",
       "            13          0.000113\n",
       "                          ...   \n",
       "1632181440  9           0.211583\n",
       "            10         -0.316795\n",
       "            11         -0.038729\n",
       "            12          0.000084\n",
       "            13         -0.000028\n",
       "Length: 98577, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_predictions(model, X, y_scale):\n",
    "    \"\"\"Undo the vol normalisation for the targets to get predictions\n",
    "    for actual returns.\n",
    "    \"\"\"\n",
    "    return model.predict(X) * y_scale\n",
    "\n",
    "\n",
    "voting_model.predict(feats.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model.fit(train)\n",
    "\n",
    "train.drop(train.index, inplace=True) # not needed so delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_n = last_n_ts_df(feats, N_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 652 ms, sys: 623 µs, total: 652 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N_TO_KEEP = 1000\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    last_n, preds = predict_loop(voting_model, last_n, test_df, sample_prediction_df, N_TO_KEEP)\n",
    "    env.predict(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "bar_feats_minimal(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(\n",
    "    columns=[\"Count\", \"Open\", \"High\", \"Low\", \"Volume\", \"VWAP\"], inplace=True\n",
    ")  # drop unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_index([\"timestamp\", \"Asset_ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ts_feats_minimal(df, window, price_mom_windows, include_target=True):\n",
    "    \"\"\"Add rolling z-score features including price momentum features and the target + target scale.\n",
    "    Assumes index is timestamps + Asset_IDs\n",
    "\n",
    "    Warning: changes input df in-place to save memory\n",
    "    \"\"\"\n",
    "    to_z_score = [\n",
    "        \"rel_avg\",\n",
    "        \"avg_t_size\",\n",
    "        \"shadow_diff\",\n",
    "        \"dollar_vol\",\n",
    "        \"rel_dev\",\n",
    "    ]\n",
    "    df_subset = df[to_z_score]\n",
    "    \n",
    "    target = df[\"Target\"] if include_target else None\n",
    "    close_prices = df[[\"Close\"]]    \n",
    "\n",
    "    log_close_grp = close_prices.groupby(level=\"Asset_ID\", as_index=False)\n",
    "\n",
    "    for mom_window in price_mom_windows:\n",
    "        feat_name = f\"price_mom_{mom_window}\"\n",
    "        df_subset.loc[:, feat_name] = log_close_grp.diff(mom_window)[\"Close\"]\n",
    "\n",
    "    min_periods = max(1, window // 10)\n",
    "    df_grp = (\n",
    "        df_subset\n",
    "        .groupby(level=\"Asset_ID\", as_index=False)\n",
    "        .rolling(window, min_periods=min_periods)\n",
    "    )\n",
    "\n",
    "    roll_mean = df_grp.mean().drop(columns=\"Asset_ID\").fillna(0).reindex(index=df.index)\n",
    "    roll_std = df_grp.std().drop(columns=\"Asset_ID\").ffill().fillna(1).reindex(index=df.index)\n",
    "\n",
    "    norm_feats = ((df_subset - roll_mean) / roll_std).rename(\n",
    "        mapper=lambda x: \"roll_\" + x, axis=\"columns\"\n",
    "    )\n",
    "\n",
    "    norm_feats.loc[:, \"target_scale\"] = roll_std[\"price_mom_15\"]\n",
    "\n",
    "    if include_target:  # FIXME: potentially confusing target naming convention\n",
    "        norm_feats.loc[:, \"scaled_target\"] = target / norm_feats[\"target_scale\"]\n",
    "        norm_feats.loc[:, \"target\"] = target\n",
    "\n",
    "    return norm_feats\n",
    "\n",
    "\n",
    "feats = ts_feats_minimal(train_data.iloc[-100000:].copy(), 120, (1, 5, 15, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feats_minimal(df, include_target=True)\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def chunk_list(l, chunk_size):\n",
    "    \"\"\"Iterate over a list in chunks\"\"\"\n",
    "    for x in range(0, len(l), chunk_size):\n",
    "        yield l[x : x + chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResultCacher:\n",
    "    \"\"\"Helper class to pickle and load a series of results to a directory in /tmp\"\"\"\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path # directory to cache intermediate results\n",
    "        self.result_paths = [] # to keep track of cached files\n",
    "        \n",
    "        self.create_save_folder()\n",
    "        \n",
    "    def create_save_folder(self):\n",
    "        os.makedirs(self.save_path)\n",
    "        \n",
    "    def get_save_path(self, filename):\n",
    "        return os.path.join(self.save_path, filename)\n",
    "        \n",
    "    def cache_result(self, result, filename):\n",
    "        \"\"\"Pickles result to given filename in save_path\"\"\"\n",
    "        file_save_path = self.get_save_path(filename)\n",
    "        logger.info(f\"Saving result to {file_save_path}\")\n",
    "        with open(file_save_path, \"wb\") as f:\n",
    "            pickle.dump(result, f)\n",
    "            \n",
    "        self.result_paths.append(file_save_path)\n",
    "            \n",
    "    def load_all_results(self):\n",
    "        \"\"\"Loads all cached results and returns as a list\"\"\"\n",
    "        results = []\n",
    "        for path in self.result_paths:\n",
    "            with open(path, \"rb\") as f:\n",
    "                results.append(pickle.load(f))\n",
    "        return results\n",
    "\n",
    "\n",
    "def chunk_ts_feats(full_df, n_splits):\n",
    "    \"\"\"Run all_feats_minimal but chunk over the original df, save intermediate results to disk,\n",
    "    and concatenate all results after finished to avoid memory issues for the full data preparation.\n",
    "    \n",
    "    Note: chunks over timestamps, not array indices to reduce potential ordering bugs.\n",
    "    \"\"\"\n",
    "    include_target = True\n",
    "    all_timestamps = np.sort(full_df[\"timestamp\"].unique())\n",
    "    chunk_size = len(all_timestamps) // n_splits + 1000 # avoid rounding issue for last chunk\n",
    "    \n",
    "    result_cacher = ResultCacher(\"/tmp/feat_cache\")\n",
    "    \n",
    "    for i, time_chunk in enumerate(chunk_list(all_timestamps, chunk_size)):   \n",
    "        df_chunk = full_df.loc[full_df.timestamp.isin(time_chunk)]\n",
    "        feat_chunk = all_feats_minimal(df_chunk, include_target=True).dropna()\n",
    "        result_cacher.cache_result(feat_chunk, f\"feat_chunk_{i}.pkl\")\n",
    "        \n",
    "    all_feats = result_cacher.load_all_results()\n",
    "    return pd.concat(all_feats)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_csv(\"train.csv\")\n",
    "td_ = td.loc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /tmp/feat_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = chunk_ts_feats(td, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>roll_rel_avg</th>\n",
       "      <th>roll_avg_t_size</th>\n",
       "      <th>roll_shadow_diff</th>\n",
       "      <th>roll_dollar_vol</th>\n",
       "      <th>roll_rel_dev</th>\n",
       "      <th>roll_price_mom_1</th>\n",
       "      <th>roll_price_mom_5</th>\n",
       "      <th>roll_price_mom_15</th>\n",
       "      <th>roll_price_mom_80</th>\n",
       "      <th>target_scale</th>\n",
       "      <th>scaled_target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th>Asset_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1514769660</th>\n",
       "      <th>2</th>\n",
       "      <td>2.299883</td>\n",
       "      <td>-0.365854</td>\n",
       "      <td>2.596611</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>1.319162</td>\n",
       "      <td>-0.291812</td>\n",
       "      <td>-0.054244</td>\n",
       "      <td>0.882758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.755681</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>-0.005769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191871</td>\n",
       "      <td>-0.237249</td>\n",
       "      <td>-1.291749</td>\n",
       "      <td>0.231149</td>\n",
       "      <td>-1.975093</td>\n",
       "      <td>-1.690940</td>\n",
       "      <td>1.098297</td>\n",
       "      <td>1.818255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.537293</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.006793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.176137</td>\n",
       "      <td>0.566540</td>\n",
       "      <td>-1.068483</td>\n",
       "      <td>0.388292</td>\n",
       "      <td>-2.639778</td>\n",
       "      <td>0.573546</td>\n",
       "      <td>1.500946</td>\n",
       "      <td>2.046108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.174588</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.076194</td>\n",
       "      <td>2.762349</td>\n",
       "      <td>-0.242970</td>\n",
       "      <td>2.556929</td>\n",
       "      <td>-0.357633</td>\n",
       "      <td>0.779032</td>\n",
       "      <td>1.229755</td>\n",
       "      <td>2.362090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.746222</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>-0.006659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514769720</th>\n",
       "      <th>2</th>\n",
       "      <td>0.943632</td>\n",
       "      <td>-0.352924</td>\n",
       "      <td>-0.357121</td>\n",
       "      <td>-0.863194</td>\n",
       "      <td>-1.653371</td>\n",
       "      <td>0.117641</td>\n",
       "      <td>0.297967</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>10.755932</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.006693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1515526200</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.472551</td>\n",
       "      <td>-1.338967</td>\n",
       "      <td>-1.188292</td>\n",
       "      <td>-1.141845</td>\n",
       "      <td>0.100857</td>\n",
       "      <td>0.037452</td>\n",
       "      <td>0.872273</td>\n",
       "      <td>-0.520037</td>\n",
       "      <td>-0.162407</td>\n",
       "      <td>31.713386</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.002134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.422216</td>\n",
       "      <td>-0.358334</td>\n",
       "      <td>0.566470</td>\n",
       "      <td>-0.780672</td>\n",
       "      <td>-1.067421</td>\n",
       "      <td>-0.253211</td>\n",
       "      <td>0.156859</td>\n",
       "      <td>-0.129053</td>\n",
       "      <td>-0.211546</td>\n",
       "      <td>0.022781</td>\n",
       "      <td>-0.235352</td>\n",
       "      <td>-0.005362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.158785</td>\n",
       "      <td>0.400971</td>\n",
       "      <td>0.602559</td>\n",
       "      <td>-0.207545</td>\n",
       "      <td>-1.039848</td>\n",
       "      <td>-1.299275</td>\n",
       "      <td>-0.947101</td>\n",
       "      <td>-2.206072</td>\n",
       "      <td>-1.920901</td>\n",
       "      <td>0.232208</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.199509</td>\n",
       "      <td>-0.169704</td>\n",
       "      <td>-1.191606</td>\n",
       "      <td>0.811255</td>\n",
       "      <td>-1.547711</td>\n",
       "      <td>-0.163019</td>\n",
       "      <td>0.511482</td>\n",
       "      <td>-0.353528</td>\n",
       "      <td>0.740363</td>\n",
       "      <td>1.870197</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.434054</td>\n",
       "      <td>2.787022</td>\n",
       "      <td>-1.473896</td>\n",
       "      <td>1.063470</td>\n",
       "      <td>0.820024</td>\n",
       "      <td>-0.049214</td>\n",
       "      <td>1.136469</td>\n",
       "      <td>-1.615445</td>\n",
       "      <td>-0.622581</td>\n",
       "      <td>0.399931</td>\n",
       "      <td>-0.006638</td>\n",
       "      <td>-0.002655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95133 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     roll_rel_avg  roll_avg_t_size  roll_shadow_diff  \\\n",
       "timestamp  Asset_ID                                                    \n",
       "1514769660 2             2.299883        -0.365854          2.596611   \n",
       "           1             1.191871        -0.237249         -1.291749   \n",
       "           6            -0.176137         0.566540         -1.068483   \n",
       "           9            -0.076194         2.762349         -0.242970   \n",
       "1514769720 2             0.943632        -0.352924         -0.357121   \n",
       "...                           ...              ...               ...   \n",
       "1515526200 1            -0.472551        -1.338967         -1.188292   \n",
       "           5             0.422216        -0.358334          0.566470   \n",
       "           7             2.158785         0.400971          0.602559   \n",
       "           6            -0.199509        -0.169704         -1.191606   \n",
       "           9             1.434054         2.787022         -1.473896   \n",
       "\n",
       "                     roll_dollar_vol  roll_rel_dev  roll_price_mom_1  \\\n",
       "timestamp  Asset_ID                                                    \n",
       "1514769660 2                0.417100      1.319162         -0.291812   \n",
       "           1                0.231149     -1.975093         -1.690940   \n",
       "           6                0.388292     -2.639778          0.573546   \n",
       "           9                2.556929     -0.357633          0.779032   \n",
       "1514769720 2               -0.863194     -1.653371          0.117641   \n",
       "...                              ...           ...               ...   \n",
       "1515526200 1               -1.141845      0.100857          0.037452   \n",
       "           5               -0.780672     -1.067421         -0.253211   \n",
       "           7               -0.207545     -1.039848         -1.299275   \n",
       "           6                0.811255     -1.547711         -0.163019   \n",
       "           9                1.063470      0.820024         -0.049214   \n",
       "\n",
       "                     roll_price_mom_5  roll_price_mom_15  roll_price_mom_80  \\\n",
       "timestamp  Asset_ID                                                           \n",
       "1514769660 2                -0.054244           0.882758           0.000000   \n",
       "           1                 1.098297           1.818255           0.000000   \n",
       "           6                 1.500946           2.046108           0.000000   \n",
       "           9                 1.229755           2.362090           0.000000   \n",
       "1514769720 2                 0.297967           0.028904           0.707107   \n",
       "...                               ...                ...                ...   \n",
       "1515526200 1                 0.872273          -0.520037          -0.162407   \n",
       "           5                 0.156859          -0.129053          -0.211546   \n",
       "           7                -0.947101          -2.206072          -1.920901   \n",
       "           6                 0.511482          -0.353528           0.740363   \n",
       "           9                 1.136469          -1.615445          -0.622581   \n",
       "\n",
       "                     target_scale  scaled_target    target  \n",
       "timestamp  Asset_ID                                         \n",
       "1514769660 2            10.755681      -0.000536 -0.005769  \n",
       "           1            60.537293      -0.000112 -0.006793  \n",
       "           6             1.174588      -0.001330 -0.001562  \n",
       "           9             0.746222      -0.008924 -0.006659  \n",
       "1514769720 2            10.755932      -0.000622 -0.006693  \n",
       "...                           ...            ...       ...  \n",
       "1515526200 1            31.713386      -0.000067 -0.002134  \n",
       "           5             0.022781      -0.235352 -0.005362  \n",
       "           7             0.232208       0.006163  0.001431  \n",
       "           6             1.870197       0.001130  0.002114  \n",
       "           9             0.399931      -0.006638 -0.002655  \n",
       "\n",
       "[95133 rows x 12 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/tmp/f3/f4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>roll_rel_avg</th>\n",
       "      <th>roll_avg_t_size</th>\n",
       "      <th>roll_shadow_diff</th>\n",
       "      <th>roll_dollar_vol</th>\n",
       "      <th>roll_rel_dev</th>\n",
       "      <th>roll_price_mom_1</th>\n",
       "      <th>roll_price_mom_5</th>\n",
       "      <th>roll_price_mom_15</th>\n",
       "      <th>roll_price_mom_80</th>\n",
       "      <th>target_scale</th>\n",
       "      <th>scaled_target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th>Asset_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1631753640</th>\n",
       "      <th>9</th>\n",
       "      <td>1597.989858</td>\n",
       "      <td>11.332906</td>\n",
       "      <td>-0.077499</td>\n",
       "      <td>14.443323</td>\n",
       "      <td>3.211268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>-0.597813</td>\n",
       "      <td>-0.007384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2677.819826</td>\n",
       "      <td>24.367717</td>\n",
       "      <td>-0.052046</td>\n",
       "      <td>16.754930</td>\n",
       "      <td>10.009002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.166166</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>0.021506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3218.460270</td>\n",
       "      <td>22.796090</td>\n",
       "      <td>-0.748666</td>\n",
       "      <td>15.042183</td>\n",
       "      <td>5.814881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>-0.060545</td>\n",
       "      <td>-0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2441.991564</td>\n",
       "      <td>33.123843</td>\n",
       "      <td>-0.981873</td>\n",
       "      <td>9.005239</td>\n",
       "      <td>4.331574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.616640</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1973.312026</td>\n",
       "      <td>16.935775</td>\n",
       "      <td>0.533226</td>\n",
       "      <td>7.425498</td>\n",
       "      <td>4.124819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.357533</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1632182400</th>\n",
       "      <th>9</th>\n",
       "      <td>-1.128889</td>\n",
       "      <td>1.634771</td>\n",
       "      <td>-1.438760</td>\n",
       "      <td>2.059398</td>\n",
       "      <td>0.325549</td>\n",
       "      <td>-0.974231</td>\n",
       "      <td>-0.609978</td>\n",
       "      <td>1.000715</td>\n",
       "      <td>-0.954430</td>\n",
       "      <td>1.166166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.124807</td>\n",
       "      <td>0.332662</td>\n",
       "      <td>-0.770455</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>-0.461169</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>1.169376</td>\n",
       "      <td>-0.687712</td>\n",
       "      <td>25.357533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.423760</td>\n",
       "      <td>1.083291</td>\n",
       "      <td>0.385268</td>\n",
       "      <td>-0.224759</td>\n",
       "      <td>0.179082</td>\n",
       "      <td>0.275001</td>\n",
       "      <td>-0.081474</td>\n",
       "      <td>0.872297</td>\n",
       "      <td>-1.288065</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.154119</td>\n",
       "      <td>-0.544943</td>\n",
       "      <td>0.301070</td>\n",
       "      <td>-0.518375</td>\n",
       "      <td>-0.580437</td>\n",
       "      <td>-0.004155</td>\n",
       "      <td>-0.419291</td>\n",
       "      <td>1.194440</td>\n",
       "      <td>-1.018470</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.818497</td>\n",
       "      <td>0.811145</td>\n",
       "      <td>0.334380</td>\n",
       "      <td>0.439168</td>\n",
       "      <td>-0.076212</td>\n",
       "      <td>0.100644</td>\n",
       "      <td>-0.230489</td>\n",
       "      <td>0.637394</td>\n",
       "      <td>-0.825192</td>\n",
       "      <td>1.616640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     roll_rel_avg  roll_avg_t_size  roll_shadow_diff  \\\n",
       "timestamp  Asset_ID                                                    \n",
       "1631753640 9          1597.989858        11.332906         -0.077499   \n",
       "           10         2677.819826        24.367717         -0.052046   \n",
       "           13         3218.460270        22.796090         -0.748666   \n",
       "           12         2441.991564        33.123843         -0.981873   \n",
       "           11         1973.312026        16.935775          0.533226   \n",
       "...                           ...              ...               ...   \n",
       "1632182400 9            -1.128889         1.634771         -1.438760   \n",
       "           10           -0.124807         0.332662         -0.770455   \n",
       "           13            0.423760         1.083291          0.385268   \n",
       "           12            0.154119        -0.544943          0.301070   \n",
       "           11            0.818497         0.811145          0.334380   \n",
       "\n",
       "                     roll_dollar_vol  roll_rel_dev  roll_price_mom_1  \\\n",
       "timestamp  Asset_ID                                                    \n",
       "1631753640 9               14.443323      3.211268               NaN   \n",
       "           10              16.754930     10.009002               NaN   \n",
       "           13              15.042183      5.814881               NaN   \n",
       "           12               9.005239      4.331574               NaN   \n",
       "           11               7.425498      4.124819               NaN   \n",
       "...                              ...           ...               ...   \n",
       "1632182400 9                2.059398      0.325549         -0.974231   \n",
       "           10               0.062493      0.167502         -0.461169   \n",
       "           13              -0.224759      0.179082          0.275001   \n",
       "           12              -0.518375     -0.580437         -0.004155   \n",
       "           11               0.439168     -0.076212          0.100644   \n",
       "\n",
       "                     roll_price_mom_5  roll_price_mom_15  roll_price_mom_80  \\\n",
       "timestamp  Asset_ID                                                           \n",
       "1631753640 9                      NaN                NaN                NaN   \n",
       "           10                     NaN                NaN                NaN   \n",
       "           13                     NaN                NaN                NaN   \n",
       "           12                     NaN                NaN                NaN   \n",
       "           11                     NaN                NaN                NaN   \n",
       "...                               ...                ...                ...   \n",
       "1632182400 9                -0.609978           1.000715          -0.954430   \n",
       "           10               -0.005104           1.169376          -0.687712   \n",
       "           13               -0.081474           0.872297          -1.288065   \n",
       "           12               -0.419291           1.194440          -1.018470   \n",
       "           11               -0.230489           0.637394          -0.825192   \n",
       "\n",
       "                     target_scale  scaled_target    target  \n",
       "timestamp  Asset_ID                                         \n",
       "1631753640 9             0.012351      -0.597813 -0.007384  \n",
       "           10            1.166166       0.018442  0.021506  \n",
       "           13            0.001950      -0.060545 -0.000118  \n",
       "           12            1.616640       0.001141  0.001845  \n",
       "           11           25.357533       0.000211  0.005342  \n",
       "...                           ...            ...       ...  \n",
       "1632182400 9             1.166166            NaN       NaN  \n",
       "           10           25.357533            NaN       NaN  \n",
       "           13            0.000771            NaN       NaN  \n",
       "           12            0.001950            NaN       NaN  \n",
       "           11            1.616640            NaN       NaN  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats#.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
